Activating virtual environment:  SNPNet
/faststorage/project/NLPPred/snp-compression/SNPNet/bin/python
Running wandb sweep
wandb: Starting wandb agent üïµÔ∏è
2022-02-20 18:04:35,793 - wandb.wandb_agent - INFO - Running runs: []
2022-02-20 18:04:36,132 - wandb.wandb_agent - INFO - Agent received command: run
2022-02-20 18:04:36,133 - wandb.wandb_agent - INFO - Agent starting run with config:
	auto_lr_find: True
	batch_size: 12
	layers_factor: 0.5
	limit_train: 20000
	max_epochs: 1
	optimizer: adamw
	p_test: 2000
	p_val: 2000
	precision: 32
	val_check_interval: 4000
	width: 64
2022-02-20 18:04:36,253 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python src/train/train.py --auto_lr_find=True --batch_size=12 --layers_factor=0.5 --limit_train=20000 --max_epochs=1 --optimizer=adamw --p_test=2000 --p_val=2000 --precision=32 --val_check_interval=4000 --width=64
2022-02-20 18:04:41,270 - wandb.wandb_agent - INFO - Running runs: ['3cfuf2qz']
wandb: Currently logged in as: kenevoldsen (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run eager-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kenevoldsen/snp-compression
wandb: üßπ View sweep at https://wandb.ai/kenevoldsen/snp-compression/sweeps/4ze1zumz
wandb: üöÄ View run at https://wandb.ai/kenevoldsen/snp-compression/runs/3cfuf2qz
wandb: Run data is saved locally in /home/kce/NLPPred/snp-compression/models/wandb/run-20220220_180442-3cfuf2qz
wandb: Run `wandb offline` to turn off syncing.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

Finding best initial lr:   0% 0/100 [00:00<?, ?it/s]Finding best initial lr:   1% 1/100 [00:00<01:21,  1.21it/s]Finding best initial lr:   2% 2/100 [00:01<01:17,  1.26it/s]Finding best initial lr:   3% 3/100 [00:02<01:15,  1.28it/s]Finding best initial lr:   4% 4/100 [00:03<01:14,  1.29it/s]Finding best initial lr:   5% 5/100 [00:03<01:13,  1.30it/s]Finding best initial lr:   6% 6/100 [00:04<01:12,  1.30it/s]Finding best initial lr:   7% 7/100 [00:05<01:11,  1.30it/s]Finding best initial lr:   8% 8/100 [00:06<01:10,  1.30it/s]Finding best initial lr:   9% 9/100 [00:06<01:09,  1.30it/s]Finding best initial lr:  10% 10/100 [00:07<01:09,  1.30it/s]Finding best initial lr:  11% 11/100 [00:08<01:08,  1.30it/s]Finding best initial lr:  12% 12/100 [00:09<01:07,  1.30it/s]Finding best initial lr:  13% 13/100 [00:10<01:06,  1.30it/s]Finding best initial lr:  14% 14/100 [00:10<01:05,  1.30it/s]Finding best initial lr:  15% 15/100 [00:11<01:05,  1.30it/s]Finding best initial lr:  16% 16/100 [00:12<01:04,  1.30it/s]Finding best initial lr:  17% 17/100 [00:13<01:03,  1.30it/s]Finding best initial lr:  18% 18/100 [00:13<01:02,  1.30it/s]Finding best initial lr:  19% 19/100 [00:14<01:02,  1.30it/s]Finding best initial lr:  20% 20/100 [00:15<01:01,  1.30it/s]Finding best initial lr:  21% 21/100 [00:16<01:00,  1.30it/s]Finding best initial lr:  22% 22/100 [00:16<00:59,  1.30it/s]Finding best initial lr:  23% 23/100 [00:17<00:59,  1.30it/s]Finding best initial lr:  24% 24/100 [00:18<00:58,  1.30it/s]Finding best initial lr:  25% 25/100 [00:19<00:57,  1.30it/s]Finding best initial lr:  26% 26/100 [00:19<00:56,  1.30it/s]Finding best initial lr:  27% 27/100 [00:20<00:55,  1.30it/s]Finding best initial lr:  28% 28/100 [00:21<00:55,  1.30it/s]Finding best initial lr:  29% 29/100 [00:22<00:54,  1.30it/s]Finding best initial lr:  30% 30/100 [00:23<00:53,  1.30it/s]Finding best initial lr:  31% 31/100 [00:23<00:52,  1.30it/s]Finding best initial lr:  32% 32/100 [00:24<00:52,  1.30it/s]Finding best initial lr:  33% 33/100 [00:25<00:51,  1.30it/s]Finding best initial lr:  34% 34/100 [00:26<00:50,  1.30it/s]Finding best initial lr:  35% 35/100 [00:26<00:49,  1.30it/s]Finding best initial lr:  36% 36/100 [00:27<00:49,  1.30it/s]Finding best initial lr:  37% 37/100 [00:28<00:48,  1.30it/s]Finding best initial lr:  38% 38/100 [00:29<00:47,  1.30it/s]Finding best initial lr:  39% 39/100 [00:29<00:46,  1.30it/s]Finding best initial lr:  40% 40/100 [00:30<00:46,  1.30it/s]Finding best initial lr:  41% 41/100 [00:31<00:45,  1.30it/s]Finding best initial lr:  42% 42/100 [00:32<00:44,  1.30it/s]Finding best initial lr:  43% 43/100 [00:33<00:43,  1.30it/s]Finding best initial lr:  44% 44/100 [00:33<00:42,  1.30it/s]Finding best initial lr:  45% 45/100 [00:34<00:42,  1.30it/s]Finding best initial lr:  46% 46/100 [00:35<00:41,  1.30it/s]Finding best initial lr:  47% 47/100 [00:36<00:40,  1.30it/s]Finding best initial lr:  48% 48/100 [00:36<00:39,  1.30it/s]Finding best initial lr:  49% 49/100 [00:37<00:39,  1.30it/s]Finding best initial lr:  50% 50/100 [00:38<00:38,  1.30it/s]Finding best initial lr:  51% 51/100 [00:39<00:37,  1.30it/s]Finding best initial lr:  52% 52/100 [00:39<00:36,  1.30it/s]Finding best initial lr:  53% 53/100 [00:40<00:36,  1.30it/s]Finding best initial lr:  54% 54/100 [00:41<00:35,  1.30it/s]Finding best initial lr:  55% 55/100 [00:42<00:34,  1.30it/s]Finding best initial lr:  56% 56/100 [00:43<00:33,  1.30it/s]Finding best initial lr:  57% 57/100 [00:43<00:32,  1.30it/s]Finding best initial lr:  58% 58/100 [00:44<00:32,  1.30it/s]Finding best initial lr:  59% 59/100 [00:45<00:31,  1.30it/s]Finding best initial lr:  60% 60/100 [00:46<00:30,  1.30it/s]Finding best initial lr:  61% 61/100 [00:46<00:29,  1.30it/s]Finding best initial lr:  62% 62/100 [00:47<00:29,  1.30it/s]Finding best initial lr:  63% 63/100 [00:48<00:28,  1.30it/s]Finding best initial lr:  64% 64/100 [00:49<00:27,  1.30it/s]Finding best initial lr:  65% 65/100 [00:49<00:26,  1.30it/s]Finding best initial lr:  66% 66/100 [00:50<00:26,  1.30it/s]Finding best initial lr:  67% 67/100 [00:51<00:25,  1.31it/s]Finding best initial lr:  68% 68/100 [00:52<00:24,  1.31it/s]Finding best initial lr:  69% 69/100 [00:52<00:23,  1.30it/s]Finding best initial lr:  70% 70/100 [00:53<00:22,  1.30it/s]Finding best initial lr:  71% 71/100 [00:54<00:22,  1.31it/s]Finding best initial lr:  72% 72/100 [00:55<00:21,  1.30it/s]Finding best initial lr:  73% 73/100 [00:56<00:20,  1.30it/s]Finding best initial lr:  74% 74/100 [00:56<00:19,  1.30it/s]Finding best initial lr:  75% 75/100 [00:57<00:19,  1.30it/s]Finding best initial lr:  76% 76/100 [00:58<00:18,  1.30it/s]Finding best initial lr:  77% 77/100 [00:59<00:17,  1.30it/s]Finding best initial lr:  78% 78/100 [00:59<00:16,  1.30it/s]Finding best initial lr:  79% 79/100 [01:00<00:16,  1.30it/s]Finding best initial lr:  80% 80/100 [01:01<00:15,  1.30it/s]Finding best initial lr:  81% 81/100 [01:02<00:14,  1.30it/s]Finding best initial lr:  82% 82/100 [01:02<00:13,  1.30it/s]Finding best initial lr:  83% 83/100 [01:03<00:13,  1.30it/s]Finding best initial lr:  84% 84/100 [01:04<00:12,  1.30it/s]Finding best initial lr:  85% 85/100 [01:05<00:11,  1.30it/s]Finding best initial lr:  86% 86/100 [01:06<00:10,  1.30it/s]Finding best initial lr:  87% 87/100 [01:06<00:09,  1.30it/s]Finding best initial lr:  88% 88/100 [01:07<00:09,  1.30it/s]Finding best initial lr:  89% 89/100 [01:08<00:08,  1.30it/s]Finding best initial lr:  90% 90/100 [01:09<00:07,  1.30it/s]Finding best initial lr:  91% 91/100 [01:09<00:06,  1.30it/s]Finding best initial lr:  92% 92/100 [01:10<00:06,  1.30it/s]Finding best initial lr:  93% 93/100 [01:11<00:05,  1.30it/s]Finding best initial lr:  94% 94/100 [01:12<00:04,  1.30it/s]Finding best initial lr:  95% 95/100 [01:12<00:03,  1.30it/s]Finding best initial lr:  96% 96/100 [01:13<00:03,  1.30it/s]Finding best initial lr:  97% 97/100 [01:14<00:02,  1.30it/s]Finding best initial lr:  98% 98/100 [01:15<00:01,  1.30it/s]Finding best initial lr:  99% 99/100 [01:15<00:00,  1.30it/s]Finding best initial lr: 100% 100/100 [01:16<00:00,  1.30it/s]Restoring states from the checkpoint path at /home/kce/NLPPred/snp-compression/models/lr_find_temp_model_16a1f92a-2865-4a29-a629-0373e7769021.ckpt
Finding best initial lr: 100% 100/100 [01:17<00:00,  1.30it/s]
[34m[1mwandb[0m: [32m[41mERROR[0m Attempted to change value of key "learning_rate" from 0.001 to 6.918309709189363e-05
[34m[1mwandb[0m: [32m[41mERROR[0m If you really want to do this, pass allow_val_change=True to config.update()
Traceback (most recent call last):
  File "src/train/train.py", line 110, in <module>
    main()
  File "src/train/train.py", line 100, in main
    config.learning_rate = lr_finder.suggestion()
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/wandb_config.py", line 142, in __setitem__
    key, val = self._sanitize(key, val)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/wandb_config.py", line 240, in _sanitize
    raise config_util.ConfigError(
wandb.sdk.lib.config_util.ConfigError: Attempted to change value of key "learning_rate" from 0.001 to 6.918309709189363e-05
If you really want to do this, pass allow_val_change=True to config.update()
wandb: Waiting for W&B process to finish, PID 68685... (failed 1). Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced eager-sweep-6: https://wandb.ai/kenevoldsen/snp-compression/runs/3cfuf2qz
wandb: Find logs at: /home/kce/NLPPred/snp-compression/models/wandb/run-20220220_180442-3cfuf2qz/logs/debug.log
wandb: 

2022-02-20 18:06:26,696 - wandb.wandb_agent - INFO - Cleaning up finished run: 3cfuf2qz
2022-02-20 18:06:31,981 - wandb.wandb_agent - INFO - Running runs: []
slurmstepd: error: *** JOB 60917742 ON s10n01 CANCELLED AT 2022-02-20T18:07:36 ***
