Activating virtual environment:  SNPNet
/faststorage/project/NLPPred/snp-compression/SNPNet/bin/python
Training SNPNet
wandb: Currently logged in as: kenevoldsen (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run hardy-morning-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kenevoldsen/snp-compression
wandb: üöÄ View run at https://wandb.ai/kenevoldsen/snp-compression/runs/vkqxe967
wandb: Run data is saved locally in /home/kce/NLPPred/snp-compression/models/wandb/run-20220221_175755-vkqxe967
wandb: Run `wandb offline` to turn off syncing.
Using 16bit native Automatic Mixed Precision (AMP)
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

FIT Profiler Report

Action                             	|  Mean duration (s)	|Num calls      	|  Total time (s) 	|  Percentage %   	|
--------------------------------------------------------------------------------------------------------------------------------------
Total                              	|  -              	|_              	|  10.46          	|  100 %          	|
--------------------------------------------------------------------------------------------------------------------------------------
get_sanity_check_batch             	|  0.64171        	|3              	|  1.9251         	|  18.405         	|
fetch_next_sanity_check_batch      	|  0.64166        	|3              	|  1.925          	|  18.404         	|
evaluation_step_and_end            	|  0.28357        	|2              	|  0.56714        	|  5.4222         	|
validation_step                    	|  0.28346        	|2              	|  0.56693        	|  5.4202         	|
run_training_epoch                 	|  0.32358        	|1              	|  0.32358        	|  3.0936         	|
get_train_batch                    	|  0.10677        	|1              	|  0.10677        	|  1.0208         	|
fetch_next_train_batch             	|  0.10671        	|1              	|  0.10671        	|  1.0202         	|
evaluation_batch_to_device         	|  0.0060179      	|2              	|  0.012036       	|  0.11507        	|
on_train_start                     	|  0.0031135      	|1              	|  0.0031135      	|  0.029767       	|
configure_optimizers               	|  0.0015688      	|1              	|  0.0015688      	|  0.014998       	|
on_validation_model_eval           	|  0.0011358      	|1              	|  0.0011358      	|  0.010859       	|
on_validation_batch_start          	|  5.8443e-05     	|2              	|  0.00011689     	|  0.0011175      	|
on_train_epoch_end                 	|  4.8317e-05     	|1              	|  4.8317e-05     	|  0.00046194     	|
configure_callbacks                	|  4.4458e-05     	|1              	|  4.4458e-05     	|  0.00042504     	|
teardown                           	|  3.8229e-05     	|1              	|  3.8229e-05     	|  0.00036549     	|
on_configure_sharded_model         	|  3.5662e-05     	|1              	|  3.5662e-05     	|  0.00034095     	|
on_pretrain_routine_start          	|  3.2352e-05     	|1              	|  3.2352e-05     	|  0.00030931     	|
setup                              	|  3.0655e-05     	|1              	|  3.0655e-05     	|  0.00029308     	|
on_train_end                       	|  3.0538e-05     	|1              	|  3.0538e-05     	|  0.00029196     	|
on_sanity_check_start              	|  2.9501e-05     	|1              	|  2.9501e-05     	|  0.00028204     	|
on_validation_end                  	|  2.7424e-05     	|1              	|  2.7424e-05     	|  0.00026219     	|
on_validation_start                	|  2.7236e-05     	|1              	|  2.7236e-05     	|  0.00026039     	|
on_before_accelerator_backend_setup	|  2.7088e-05     	|1              	|  2.7088e-05     	|  0.00025898     	|
on_epoch_start                     	|  1.2539e-05     	|2              	|  2.5079e-05     	|  0.00023977     	|
on_validation_batch_end            	|  1.249e-05      	|2              	|  2.498e-05      	|  0.00023882     	|
on_validation_epoch_end            	|  2.4967e-05     	|1              	|  2.4967e-05     	|  0.0002387      	|
on_epoch_end                       	|  1.0401e-05     	|2              	|  2.0802e-05     	|  0.00019888     	|
validation_step_end                	|  8.3549e-06     	|2              	|  1.671e-05      	|  0.00015976     	|
on_pretrain_routine_end            	|  1.5164e-05     	|1              	|  1.5164e-05     	|  0.00014497     	|
on_sanity_check_end                	|  1.4318e-05     	|1              	|  1.4318e-05     	|  0.00013689     	|
on_validation_epoch_start          	|  1.386e-05      	|1              	|  1.386e-05      	|  0.00013251     	|
configure_sharded_model            	|  1.2305e-05     	|1              	|  1.2305e-05     	|  0.00011764     	|
prepare_data                       	|  1.1552e-05     	|1              	|  1.1552e-05     	|  0.00011044     	|
on_val_dataloader                  	|  1.1103e-05     	|1              	|  1.1103e-05     	|  0.00010615     	|
val_dataloader                     	|  9.9503e-06     	|1              	|  9.9503e-06     	|  9.513e-05      	|
on_train_epoch_start               	|  5.5339e-06     	|1              	|  5.5339e-06     	|  5.2907e-05     	|
on_train_dataloader                	|  5.3681e-06     	|1              	|  5.3681e-06     	|  5.1322e-05     	|
train_dataloader                   	|  3.688e-06      	|1              	|  3.688e-06      	|  3.526e-05      	|

LR finder stopped early after 0 steps due to diverging loss.
Restoring states from the checkpoint path at /home/kce/NLPPred/snp-compression/models/lr_find_temp_model_632c45d7-82f9-40a4-8dc6-4b520bfb98e9.ckpt
Failed to compute suggesting for `lr`. There might not be enough points.
Traceback (most recent call last):
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py", line 176, in suggestion
    min_grad = np.gradient(loss).argmin()
  File "<__array_function__ internals>", line 180, in gradient
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/numpy/lib/function_base.py", line 1195, in gradient
    raise ValueError(
ValueError: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.
Failed to compute suggesting for `lr`. There might not be enough points.
Traceback (most recent call last):
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py", line 176, in suggestion
    min_grad = np.gradient(loss).argmin()
  File "<__array_function__ internals>", line 180, in gradient
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/numpy/lib/function_base.py", line 1195, in gradient
    raise ValueError(
ValueError: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name     | Type                 | Params
--------------------------------------------------
0 | model    | DenoisingAutoencoder | 574 K 
1 | loss     | CrossEntropyLoss     | 0     
2 | accuracy | Accuracy             | 0     
3 | f1       | F1Score              | 0     
4 | conf_mat | ConfusionMatrix      | 0     
--------------------------------------------------
574 K     Trainable params
0         Non-trainable params
574 K     Total params
1.148     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0% 0/2 [00:00<?, ?it/s]/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning:

There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

Traceback (most recent call last):
  File "src/train/train.py", line 111, in <module>
    main()
  File "src/train/train.py", line 104, in main
    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 740, in fit
    self._call_and_handle_interrupt(
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 685, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 777, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1199, in _run
    self._dispatch()
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1279, in _dispatch
    self.training_type_plugin.start_training(self)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1289, in run_stage
    return self._run_train()
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1311, in _run_train
    self._run_sanity_check(self.lightning_module)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1375, in _run_sanity_check
    self._evaluation_loop.run()
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 110, in advance
    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 122, in advance
    output = self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 217, in _evaluation_step
    output = self.trainer.accelerator.validation_step(step_kwargs)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 239, in validation_step
    return self.training_type_plugin.validation_step(*step_kwargs.values())
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 219, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "./src/models/pl_wrappers.py", line 119, in validation_step
    self.logger.experiment.log({"conf_matrix": fig})
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 1349, in log
    self.history._row_add(data)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/wandb_history.py", line 44, in _row_add
    self._flush()
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/wandb_history.py", line 59, in _flush
    self._callback(row=self._data, step=self._step)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 1027, in _history_callback
    self._backend.interface.publish_history(
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 496, in publish_history
    data = data_types.history_dict_to_json(run, data, step=step)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/data_types.py", line 2591, in history_dict_to_json
    payload[key] = val_to_json(run, key, val, namespace=step)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/data_types.py", line 2616, in val_to_json
    val = Plotly.make_plot_media(val)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/sdk/data_types.py", line 2540, in make_plot_media
    val = util.matplotlib_to_plotly(val)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/wandb/util.py", line 510, in matplotlib_to_plotly
    return tools.mpl_to_plotly(obj)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/plotly/tools.py", line 112, in mpl_to_plotly
    matplotlylib.Exporter(renderer).run(fig)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/plotly/matplotlylib/mplexporter/exporter.py", line 53, in run
    self.crawl_fig(fig)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/plotly/matplotlylib/mplexporter/exporter.py", line 124, in crawl_fig
    self.crawl_ax(ax)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/plotly/matplotlylib/mplexporter/exporter.py", line 146, in crawl_ax
    self.draw_collection(ax, collection)
  File "/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/plotly/matplotlylib/mplexporter/exporter.py", line 289, in draw_collection
    offset_order = offset_dict[collection.get_offset_position()]
AttributeError: 'QuadMesh' object has no attribute 'get_offset_position'
wandb: ERROR Problem finishing run
/home/kce/miniconda3/envs/snp-compression/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
