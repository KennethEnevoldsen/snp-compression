Activating virtual environment:  SNPNet
/faststorage/project/NLPPred/snp-compression/SNPNet/bin/python
compressing chromosomes
/faststorage/project/NLPPred/snp-compression/SNPNet/lib/python3.8/site-packages/xarray/core/indexing.py:1228: PerformanceWarning: Slicing is producing a large chunk. To accept the large
chunk and silence this warning, set the option
    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):
    ...     array[indexer]

To avoid creating the large chunks, set the option
    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):
    ...     array[indexer]
  return self.array[key]
loading model
Loading data
Traceback (most recent call last):
  File "src/apply/validate.py", line 90, in <module>
    loader = ds.create_data_array_iter(batch_size=64)
  File "./src/data/dataloaders.py", line 165, in create_data_array_iter
    dataset_iter = self.batch_iter(dataset_iter, batch_size)
TypeError: batch_iter() takes 2 positional arguments but 3 were given
