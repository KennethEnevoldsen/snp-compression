wandb: Currently logged in as: kenevoldsen (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run devoted-wind-88
wandb: ⭐️ View project at https://wandb.ai/kenevoldsen/snp-compression-src_models
wandb: 🚀 View run at https://wandb.ai/kenevoldsen/snp-compression-src_models/runs/zvwb9vkm
wandb: Run data is saved locally in /faststorage/project/NLPPred/snp-compression/wandb/run-20220211_181605-zvwb9vkm
wandb: Run `wandb offline` to turn off syncing.
./src/data/dataloaders.py:121: PerformanceWarning: Slicing is producing a large chunk. To accept the large
chunk and silence this warning, set the option
    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):
    ...     array[indexer]

To avoid creating the large chunks, set the option
    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):
    ...     array[indexer]
  train = arr[splits == 0].rechunk()
/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/deprecate/deprecation.py:115: FutureWarning: The `F1` was deprecated since v0.7 in favor of `torchmetrics.classification.f_beta.F1Score`. It will be removed in v0.8.
  stream(template_mgs % msg_args)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
Set SLURM handle signals.

  | Name     | Type                 | Params
--------------------------------------------------
0 | model    | DenoisingAutoencoder | 574 K 
1 | loss     | CrossEntropyLoss     | 0     
2 | accuracy | Accuracy             | 0     
3 | f1       | F1                   | 0     
4 | pearson  | PearsonCorrCoef      | 0     
--------------------------------------------------
574 K     Trainable params
0         Non-trainable params
574 K     Total params
2.297     Total estimated model params size (MB)

Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0% 0/2 [00:00<?, ?it/s]Traceback (most recent call last):
  File "src/models/train_SNPNet.py", line 101, in <module>
    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
    self._run(model)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 918, in _run
    self._dispatch()
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
    self.accelerator.start_training(self)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 92, in start_training
    self.training_type_plugin.start_training(trainer)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 161, in start_training
    self._results = trainer.run_stage()
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 996, in run_stage
    return self._run_train()
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1031, in _run_train
    self._run_sanity_check(self.lightning_module)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1115, in _run_sanity_check
    self._evaluation_loop.run()
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 110, in advance
    dl_outputs = self.epoch_loop.run(
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 110, in advance
    output = self.evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 154, in evaluation_step
    output = self.trainer.accelerator.validation_step(step_kwargs)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 211, in validation_step
    return self.training_type_plugin.validation_step(*step_kwargs.values())
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 178, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "./src/models/models/pl_wrappers.py", line 72, in validation_step
    x_hat = self.forward(x)
  File "./src/models/models/pl_wrappers.py", line 27, in forward
    return self.model(x)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "./src/models/models/DenoisingAutoencoder.py", line 47, in forward
    x = self.encoder(x)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "./src/models/models/SNPNet.py", line 307, in forward
    x = self.conv1(x)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "./src/models/models/SNPNet.py", line 45, in forward
    x = self.conv(x)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/kce/miniconda3/envs/snp-compression/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 395, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
TypeError: conv2d(): argument 'padding' (position 5) must be tuple of ints, not str
wandb: Waiting for W&B process to finish, PID 59347... (failed 1). Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced devoted-wind-88: https://wandb.ai/kenevoldsen/snp-compression-src_models/runs/zvwb9vkm
wandb: Find logs at: ./wandb/run-20220211_181605-zvwb9vkm/logs/debug.log
wandb: 

